{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAIHNZKcwN5A",
    "outputId": "befc7c76-eb21-4cca-fea2-73e8e2f92ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autokeras in c:\\github\\python\\lecture\\venv\\lib\\site-packages (1.0.14)\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from autokeras) (2.4.0)\n",
      "Requirement already satisfied: keras-tuner>=1.0.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from autokeras) (1.0.2)\n",
      "Requirement already satisfied: pandas in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from autokeras) (1.2.4)\n",
      "Requirement already satisfied: packaging in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from autokeras) (20.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from autokeras) (0.24.2)\n",
      "Requirement already satisfied: requests in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (2.25.1)\n",
      "Requirement already satisfied: tabulate in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (0.8.9)\n",
      "Requirement already satisfied: future in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (0.18.2)\n",
      "Requirement already satisfied: colorama in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (0.4.4)\n",
      "Requirement already satisfied: numpy in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (1.19.5)\n",
      "Requirement already satisfied: terminaltables in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (3.1.0)\n",
      "Requirement already satisfied: scipy in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (1.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from keras-tuner>=1.0.2->autokeras) (4.61.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (2.5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (0.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (3.17.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (57.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.30.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from requests->keras-tuner>=1.0.2->autokeras) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from packaging->autokeras) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from pandas->autokeras) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from pandas->autokeras) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from scikit-learn->autokeras) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\github\\python\\lecture\\venv\\lib\\site-packages (from scikit-learn->autokeras) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_RXtLxQJwN5C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import autokeras as ak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx27o9E8wN5C"
   },
   "source": [
    "## A Simple Example\n",
    "The first step is to prepare your data. Here we use the MNIST dataset as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QblZaGyswN5C",
    "outputId": "19ffdb52-b8bb-404d-a1a7-ae1703d4f6e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTjO6fSHwN5D"
   },
   "source": [
    "The second step is to run the ImageClassifier.\n",
    "It is recommended have more trials for more complicated datasets.\n",
    "This is just a quick demo of MNIST, so we set max_trials to 1.\n",
    "For the same reason, we set epochs to 10.\n",
    "You can also leave the epochs unspecified for an adaptive number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyDAnI2kwN5D",
    "outputId": "ccdcd56c-6225-4bbb-c49e-6cfe4f76ce48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "image_block_1/b...|vanilla           |?                 \n",
      "image_block_1/n...|True              |?                 \n",
      "image_block_1/a...|False             |?                 \n",
      "image_block_1/c...|3                 |?                 \n",
      "image_block_1/c...|1                 |?                 \n",
      "image_block_1/c...|2                 |?                 \n",
      "image_block_1/c...|True              |?                 \n",
      "image_block_1/c...|False             |?                 \n",
      "image_block_1/c...|0.25              |?                 \n",
      "image_block_1/c...|32                |?                 \n",
      "image_block_1/c...|64                |?                 \n",
      "classification_...|flatten           |?                 \n",
      "classification_...|0.5               |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d38c1416d16e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mak\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Feed the image classifier with training data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\autokeras\\tasks\\image.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m                 [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n\u001b[0;32m    158\u001b[0m         \"\"\"\n\u001b[1;32m--> 159\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\autokeras\\auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m             )\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         self.tuner.search(\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         super().search(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         )\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         _, history = utils.fit_with_adaptive_batch_size(\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(model, dataset)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocessingLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m                 \u001b[0mtemp_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_output_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, batch_size, steps, reset_state)\u001b[0m\n\u001b[0;32m    269\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compile with defaults.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     data_handler = data_adapter.DataHandler(\n\u001b[0;32m    273\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36m_reset_state_wrapper\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reset_state_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;34m\"\"\"Calls `reset_state` and sets `adapted` to `False`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_state_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_adapted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github\\python\\lecture\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36mreset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=method-hidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;34m\"\"\"Resets the statistics of the preprocessing layer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmerge_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
    "# Feed the image classifier with training data.\n",
    "clf.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)\n",
    "\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIhylTn-wN5D"
   },
   "source": [
    "## Validation Data\n",
    "By default, AutoKeras use the last 20% of training data as validation data. As\n",
    "shown in the example below, you can use validation_split to specify the\n",
    "percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmiTj9RCwN5E"
   },
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN1x_L1BwN5E"
   },
   "source": [
    "You can also use your own validation set instead of splitting it from the\n",
    "training data with validation_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivnMSDidwN5E"
   },
   "outputs": [],
   "source": [
    "split = 50000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_1WNWDawN5E"
   },
   "source": [
    "## Customized Search Space\n",
    "For advanced users, you may customize your search space by using AutoModel\n",
    "instead of ImageClassifier. You can configure the ImageBlock for some\n",
    "high-level configurations, e.g., block_type for the type of neural network to\n",
    "search, normalize for whether to do data normalization, augment for whether to\n",
    "do data augmentation. You can also do not specify these arguments, which would\n",
    "leave the different choices to be tuned automatically. See the following\n",
    "example for detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYV9tW81wN5E"
   },
   "outputs": [],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    # Only search ResNet architectures.\n",
    "    block_type=\"resnet\",\n",
    "    # Normalize the dataset.\n",
    "    normalize=True,\n",
    "    # Do not do data augmentation.\n",
    "    augment=False,\n",
    ")(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIa_5AHzwN5F"
   },
   "source": [
    "The usage of AutoModel is similar to the functional API of Keras. Basically, you are\n",
    "building a graph, whose edges are blocks and the nodes are intermediate outputs of\n",
    "blocks. To add an edge from input_node to output_node with output_node =\n",
    "ak.[some_block]([block_args])(input_node).\n",
    "\n",
    "You can even also use more fine grained blocks to customize the search space even\n",
    "further. See the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H477pt-JwN5F"
   },
   "outputs": [],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
    "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJcXE5qgwN5F"
   },
   "source": [
    "## Data Format\n",
    "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
    "\n",
    "For the image, it accepts data formats both with and without the channel\n",
    "dimension. The images in the MNIST dataset do not have the channel dimension.\n",
    "Each image is a matrix with shape (28, 28). AutoKeras also accepts images of\n",
    "three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28,\n",
    "28, 1).\n",
    "\n",
    "For the classification labels, AutoKeras accepts both plain labels, i.e.\n",
    "strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and\n",
    "1s.\n",
    "\n",
    "So if you prepare your data in the following way, the ImageClassifier should\n",
    "still work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZ6ZuIwzwN5F"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the images to have the channel dimension.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "# One-hot encode the labels.\n",
    "eye = np.eye(10)\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28, 1)\n",
    "print(y_train.shape)  # (60000, 10)\n",
    "print(y_train[:3])\n",
    "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-b93wQDwN5G"
   },
   "source": [
    "We also support using tf.data.Dataset format for the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRXFZ1R7wN5G"
   },
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,)))\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,)))\n",
    "\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=10)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5TslbQjwN5G"
   },
   "source": [
    "## Reference\n",
    "[ImageClassifier](/image_classifier),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[ImageBlock](/block/#imageblock-class),\n",
    "[Normalization](/block/#normalization-class),\n",
    "[ImageAugmentation](/block/#image-augmentation-class),\n",
    "[ResNetBlock](/block/#resnetblock-class),\n",
    "[ImageInput](/node/#imageinput-class),\n",
    "[ClassificationHead](/block/#classificationhead-class).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
